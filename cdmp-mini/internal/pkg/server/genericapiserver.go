package server

import (
	"context"
	"sync"

	"fmt"
	"net"
	"net/http"
	"path/filepath"
	"strconv"
	"strings"
	"time"

	"github.com/gin-gonic/gin"
	"github.com/go-redis/redis/v8"

	"github.com/maxiaolu1981/cretem/cdmp-mini/internal/apiserver/options"
	mysql "github.com/maxiaolu1981/cretem/cdmp-mini/internal/apiserver/store"
	"github.com/maxiaolu1981/cretem/cdmp-mini/internal/apiserver/store/interfaces"
	"github.com/maxiaolu1981/cretem/cdmp-mini/internal/pkg/code"
	"github.com/maxiaolu1981/cretem/cdmp-mini/internal/pkg/metrics"
	"github.com/maxiaolu1981/cretem/cdmp-mini/internal/pkg/middleware"

	"github.com/maxiaolu1981/cretem/cdmp-mini/pkg/log"
	"github.com/maxiaolu1981/cretem/cdmp-mini/pkg/storage"
	"github.com/maxiaolu1981/cretem/nexuscore/errors"
	"golang.org/x/sync/errgroup"
	"gorm.io/gorm"
)

type GenericAPIServer struct {
	insecureServer *http.Server
	*gin.Engine
	options        *options.Options
	redis          *storage.RedisCluster
	redisCancel    context.CancelFunc
	initOnce       sync.Once
	producer       *UserProducer
	consumerCtx    context.Context
	consumerCancel context.CancelFunc
	createConsumer *UserConsumer
	updateConsumer *UserConsumer
	deleteConsumer *UserConsumer
	retryConsumer  *RetryConsumer
}

func NewGenericAPIServer(opts *options.Options) (*GenericAPIServer, error) {
	// åˆå§‹åŒ–æ—¥å¿—
	log.Infof("æ­£åœ¨åˆå§‹åŒ–GenericAPIServeræœåŠ¡å™¨ï¼Œç¯å¢ƒ: %s", opts.ServerRunOptions.Mode)

	//åˆ›å»ºæœåŠ¡å™¨å®ä¾‹
	g := &GenericAPIServer{
		Engine:   gin.New(),
		options:  opts,
		initOnce: sync.Once{},
	}

	//è®¾ç½®ginè¿è¡Œæ¨¡å¼
	if err := g.configureGin(); err != nil {
		return nil, err
	}

	//åˆå§‹åŒ–mysql
	storeIns, dbIns, err := mysql.GetMySQLFactoryOr(opts.MysqlOptions)
	if err != nil {
		log.Error("mysqlæœåŠ¡å™¨å¯åŠ¨å¤±è´¥")
		return nil, err
	}
	interfaces.SetClient(storeIns)
	log.Info("mysqlæœåŠ¡å™¨åˆå§‹åŒ–æˆåŠŸ")

	//åˆå§‹åŒ–redis
	if err := g.initRedisStore(); err != nil {
		log.Error("redisæœåŠ¡å™¨å¯åŠ¨å¤±è´¥")
		return nil, err
	}
	log.Info("redisæœåŠ¡å™¨å¯åŠ¨æˆåŠŸ")

	// åˆå§‹åŒ–Kafkaç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…
	if err := InitKafkaWithRetry(opts); err != nil {
		log.Error("kafkaæµ‹è¯•è¿é€šå¤±è´¥")
		return nil, errors.WithCode(code.ErrKafkaFailed, "kafkaæœåŠ¡æœªå¯åŠ¨")
	}

	if err := g.initKafkaComponents(dbIns); err != nil {
		log.Error("kafkaæœåŠ¡å¯åŠ¨å¤±è´¥")
		return nil, err
	}
	log.Info("kafkaæœåŠ¡å™¨å¯åŠ¨æˆåŠŸ")
	// å¯åŠ¨æ¶ˆè´¹è€…
	ctx, cancel := context.WithCancel(context.Background())
	g.consumerCtx = ctx
	g.consumerCancel = cancel
	// å¯åŠ¨æ¶ˆè´¹è€…ï¼Œä½¿ç”¨é…ç½®çš„WorkerCount
	mainWorkers := opts.KafkaOptions.WorkerCount
	if mainWorkers <= 0 {
		mainWorkers = MainConsumerWorkers // ä½¿ç”¨é»˜è®¤å€¼
	}

	go g.createConsumer.StartConsuming(ctx, mainWorkers)
	go g.updateConsumer.StartConsuming(ctx, mainWorkers)
	go g.deleteConsumer.StartConsuming(ctx, mainWorkers)
	go g.retryConsumer.StartConsuming(ctx, RetryConsumerWorkers)

	log.Info("æ‰€æœ‰Kafkaæ¶ˆè´¹è€…å·²å¯åŠ¨")

	//å»¶è¿Ÿ3ç§’
	time.Sleep(3 * time.Second)
	g.printKafkaConfigInfo()

	//å®‰è£…ä¸­é—´ä»¶
	if err := middleware.InstallMiddlewares(g.Engine, opts); err != nil {
		log.Error("ä¸­é—´ä»¶å®‰è£…å¤±è´¥")
		return nil, err
	}
	log.Info("ä¸­é—´ä»¶å®‰è£…æˆåŠŸ")

	//. å®‰è£…è·¯ç”±
	g.installRoutes()

	return g, nil
}

func (g *GenericAPIServer) configureGin() error {
	// è®¾ç½®è¿è¡Œæ¨¡å¼
	gin.SetMode(g.options.ServerRunOptions.Mode)

	// å¼€å‘ç¯å¢ƒé…ç½®
	if g.options.ServerRunOptions.Mode == gin.DebugMode {
		gin.DebugPrintRouteFunc = func(httpMethod, absolutePath, handlerName string, nuHandlers int) {
			log.Debugf("ğŸ“ %-6s %-50s â†’ %s (%d middleware)",
				httpMethod, absolutePath, filepath.Base(handlerName), nuHandlers)
		}
	} else {
		// ç”Ÿäº§ç¯å¢ƒç¦ç”¨è°ƒè¯•è¾“å‡º
		gin.DebugPrintRouteFunc = func(httpMethod, absolutePath, handlerName string, nuHandlers int) {}
	}

	return nil
}

func (g *GenericAPIServer) Run() error {
	address := net.JoinHostPort(g.options.InsecureServingOptions.BindAddress, strconv.Itoa((g.options.InsecureServingOptions.BindPort)))

	g.insecureServer = &http.Server{
		Addr:    address,
		Handler: g,
		// æœåŠ¡å™¨æ€§èƒ½ä¼˜åŒ–
		ReadTimeout:       15 * time.Second,
		ReadHeaderTimeout: 10 * time.Second,
		WriteTimeout:      15 * time.Second,
		IdleTimeout:       30 * time.Second,

		// è¿æ¥æ§åˆ¶
		MaxHeaderBytes: 1 << 20, // 1MB
		// æ–°å¢ï¼šè¿æ¥æ•°é™åˆ¶
		ConnState: func(conn net.Conn, state http.ConnState) {
			// ç›‘æ§è¿æ¥çŠ¶æ€ï¼Œé˜²æ­¢è¿‡å¤šè¿æ¥
		},
	}

	var eg errgroup.Group

	// åˆ›å»ºæœåŠ¡å™¨å¯åŠ¨ä¿¡å·é€šé“
	serverStarted := make(chan struct{})

	eg.Go(func() error {
		log.Infof("æ­£åœ¨ %s å¯åŠ¨ GenericAPIServer æœåŠ¡", address)

		// åˆ›å»ºç›‘å¬å™¨ï¼Œç¡®ä¿ç«¯å£å¯ç”¨
		listener, err := net.Listen("tcp", address)
		if err != nil {
			return fmt.Errorf("åˆ›å»ºç›‘å¬å™¨å¤±è´¥: %w", err)
		}

		log.Info("ç«¯å£ç›‘å¬æˆåŠŸï¼Œå¼€å§‹æ¥å—è¿æ¥")
		close(serverStarted)

		// å¯åŠ¨æœåŠ¡å™¨
		err = g.insecureServer.Serve(listener)
		if errors.Is(err, http.ErrServerClosed) {
			log.Infof("GenericAPIServeræœåŠ¡å™¨å·²æ­£å¸¸å…³é—­")
			return nil
		}
		if err != nil {
			return fmt.Errorf("GenericAPIServeræœåŠ¡å™¨å¯åŠ¨å¤±è´¥: %w", err)
		}

		log.Infof("åœæ­¢ %s è¿è¡Œçš„ GenericAPIServer æœåŠ¡", address)
		return nil
	})

	// ç­‰å¾…æœåŠ¡å™¨å¼€å§‹ç›‘å¬
	select {
	case <-serverStarted:
		log.Info("GenericAPIServeræœåŠ¡å™¨å·²å¼€å§‹ç›‘å¬ï¼Œå‡†å¤‡è¿›è¡Œå¥åº·æ£€æŸ¥...")
	case <-time.After(10 * time.Second):
		return fmt.Errorf("GenericAPIServeræœåŠ¡å™¨å¯åŠ¨è¶…æ—¶ï¼Œæ— æ³•åœ¨5ç§’å†…å¼€å§‹ç›‘å¬")
	}

	if g.options.ServerRunOptions.Healthz {
		ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
		defer cancel()

		// å…ˆç­‰å¾…ç«¯å£å°±ç»ª
		if err := g.waitForPortReady(ctx, address, 10*time.Second); err != nil {
			return fmt.Errorf("ç«¯å£å°±ç»ªæ£€æµ‹å¤±è´¥: %w", err)
		}

		// æ‰§è¡Œå¥åº·æ£€æŸ¥
		if err := g.ping(ctx, address); err != nil {
			return fmt.Errorf("å¥åº·æ£€æŸ¥å¤±è´¥: %w", err)
		}
	}

	if err := eg.Wait(); err != nil {
		return fmt.Errorf("æœåŠ¡å™¨è¿è¡Œé”™è¯¯: %w", err)
	}
	return nil
}

// waitForPortReady ç­‰å¾…ç«¯å£å°±ç»ª
func (g *GenericAPIServer) waitForPortReady(ctx context.Context, address string, timeout time.Duration) error {
	deadline := time.Now().Add(timeout)
	log.Infof("ç­‰å¾…ç«¯å£ %s å°±ç»ªï¼Œè¶…æ—¶æ—¶é—´: %v", address, timeout)

	for attempt := 1; ; attempt++ {
		// æ£€æŸ¥æ˜¯å¦è¶…æ—¶
		if time.Now().After(deadline) {
			return fmt.Errorf("ç«¯å£å°±ç»ªæ£€æµ‹è¶…æ—¶")
		}

		// å°è¯•è¿æ¥ç«¯å£
		conn, err := net.DialTimeout("tcp", address, 100*time.Millisecond)
		if err == nil {
			conn.Close()
			log.Infof("ç«¯å£ %s å°±ç»ªæ£€æµ‹æˆåŠŸï¼Œå°è¯•æ¬¡æ•°: %d", address, attempt)
			return nil
		}

		// è®°å½•é‡è¯•ä¿¡æ¯ï¼ˆæ¯5æ¬¡å°è¯•è®°å½•ä¸€æ¬¡ï¼‰
		if attempt%5 == 0 {
			log.Infof("ç«¯å£å°±ç»ªæ£€æµ‹å°è¯• %d: %v", attempt, err)
		}

		// ç­‰å¾…é‡è¯•æˆ–ä¸Šä¸‹æ–‡å–æ¶ˆ
		select {
		case <-ctx.Done():
			return fmt.Errorf("ç«¯å£å°±ç»ªæ£€æµ‹è¢«å–æ¶ˆ: %w", ctx.Err())
		case <-time.After(100 * time.Millisecond):
			// ç»§ç»­é‡è¯•
		}
	}
}

// åˆå§‹åŒ–Kafkaç»„ä»¶
// internal/apiserver/server/server.go

// åˆå§‹åŒ–Kafkaç»„ä»¶ - ä½¿ç”¨optionsä¸­çš„å®Œæ•´é…ç½®
func (g *GenericAPIServer) initKafkaComponents(db *gorm.DB) error {
	kafkaOpts := g.options.KafkaOptions

	log.Infof("åˆå§‹åŒ–Kafkaç»„ä»¶ï¼Œæœ€å¤§é‡è¯•: %d, Workeræ•°é‡: %d",
		kafkaOpts.MaxRetries, kafkaOpts.WorkerCount)

	// 1. åˆå§‹åŒ–ç”Ÿäº§è€…
	log.Info("åˆå§‹åŒ–Kafkaç”Ÿäº§è€…...")
	userProducer := NewUserProducer(kafkaOpts)

	// 2. åˆå§‹åŒ–å„ä¸ªä¸»é¢˜çš„æ¶ˆè´¹è€…
	consumerGroupPrefix := "user-service"
	if g.options.ServerRunOptions.Mode == gin.ReleaseMode {
		consumerGroupPrefix = "user-service-prod"
	}

	log.Info("åˆå§‹åŒ–åˆ›å»ºæ¶ˆè´¹è€…...")
	createConsumer := NewUserConsumer(kafkaOpts.Brokers, UserCreateTopic,
		consumerGroupPrefix+"-create", db, g.redis)
	//createConsumer.SetKafkaOptions(kafkaOpts) // ä¼ é€’å®Œæ•´é…ç½®
	createConsumer.SetProducer(userProducer)

	log.Info("åˆå§‹åŒ–æ›´æ–°æ¶ˆè´¹è€…...")
	updateConsumer := NewUserConsumer(kafkaOpts.Brokers, UserUpdateTopic,
		consumerGroupPrefix+"-update", db, g.redis)
	//updateConsumer.SetKafkaOptions(kafkaOpts)
	updateConsumer.SetProducer(userProducer)

	log.Info("åˆå§‹åŒ–åˆ é™¤æ¶ˆè´¹è€…...")
	deleteConsumer := NewUserConsumer(kafkaOpts.Brokers, UserDeleteTopic,
		consumerGroupPrefix+"-delete", db, g.redis)
	//deleteConsumer.SetKafkaOptions(kafkaOpts)
	deleteConsumer.SetProducer(userProducer)

	log.Info("åˆå§‹åŒ–é‡è¯•æ¶ˆè´¹è€…...")
	retryConsumer := NewRetryConsumer(db, g.redis, userProducer, kafkaOpts)
	//retryConsumer.SetKafkaOptions(kafkaOpts) // ä¼ é€’é…ç½®ç»™é‡è¯•æ¶ˆè´¹è€…

	// 3. èµ‹å€¼åˆ°æœåŠ¡å™¨å®ä¾‹
	g.producer = userProducer
	g.createConsumer = createConsumer
	g.updateConsumer = updateConsumer
	g.deleteConsumer = deleteConsumer
	g.retryConsumer = retryConsumer

	log.Infof("âœ… Kafkaç»„ä»¶åˆå§‹åŒ–å®Œæˆï¼Œé…ç½®: é‡è¯•%dæ¬¡, Worker%dä¸ª, æ‰¹é‡%d, è¶…æ—¶%v",
		kafkaOpts.MaxRetries, kafkaOpts.WorkerCount, kafkaOpts.BatchSize, kafkaOpts.BatchTimeout)
	return nil
}

// monitorRedisConnection ç›‘æ§Redisè¿æ¥çŠ¶æ€ï¼Œæ ¹æ®åˆ†å¸ƒå¼é”å¼€å…³å†³å®šæ˜¯å¦å½±å“ä¸»è¿›ç¨‹
func (g *GenericAPIServer) monitorRedisConnection(ctx context.Context) {
	ticker := time.NewTicker(30 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			log.Info("Redisé›†ç¾¤ç›‘æ§é€€å‡º")
			return
		case <-ticker.C:
			client := g.redis.GetClient()
			if client == nil {
				log.Error("Redisé›†ç¾¤å®¢æˆ·ç«¯ä¸¢å¤±")
				continue
			}

			if err := g.pingRedis(ctx, client); err != nil {
				log.Errorf("Redisé›†ç¾¤å¥åº·æ£€æŸ¥å¤±è´¥: %v", err)
				// è¿™é‡Œå¯ä»¥æ·»åŠ é‡è¿é€»è¾‘
			} else {
				log.Debug("Redisé›†ç¾¤å¥åº·æ£€æŸ¥é€šè¿‡")
			}
		}
	}
}

// handlePingError åˆ†ç±»å¤„ç†PINGå‘½ä»¤çš„é”™è¯¯
func handlePingError(err error) error {
	if err == nil {
		return nil
	}

	if strings.Contains(err.Error(), "connection refused") ||
		strings.Contains(err.Error(), "i/o timeout") ||
		strings.Contains(err.Error(), "closed") {
		return fmt.Errorf("è¿æ¥å¤±è´¥: %v", err)
	}
	return fmt.Errorf("PINGå¤±è´¥: %v", err)
}

func (g *GenericAPIServer) ping(ctx context.Context, address string) error {
	host, port, err := net.SplitHostPort(address)
	if err != nil {
		return fmt.Errorf("æ— æ•ˆçš„åœ°å€æ ¼å¼: %w", err)
	}

	if host == "0.0.0.0" {
		host = "127.0.0.1"
	}

	url := fmt.Sprintf("http://%s/healthz", net.JoinHostPort(host, port))
	log.Infof("å¼€å§‹å¥åº·æ£€æŸ¥ï¼Œç›®æ ‡URL: %s", url)

	startTime := time.Now()
	attempt := 0

	for {
		attempt++
		if err := ctx.Err(); err != nil {
			return fmt.Errorf("å¥åº·æ£€æŸ¥è¶…æ—¶: %w", err)
		}

		req, err := http.NewRequestWithContext(ctx, http.MethodGet, url, nil)
		if err != nil {
			return fmt.Errorf("åˆ›å»ºè¯·æ±‚å¤±è´¥: %w", err)
		}

		resp, err := http.DefaultClient.Do(req)
		if err != nil {
			if attempt%3 == 0 { // æ¯3æ¬¡å¤±è´¥è®°å½•ä¸€æ¬¡æ—¥å¿—ï¼Œé¿å…æ—¥å¿—è¿‡å¤š
				log.Infof("å¥åº·æ£€æŸ¥å°è¯• %d å¤±è´¥: %v", attempt, err)
			}
		} else {
			defer resp.Body.Close()

			if resp.StatusCode == http.StatusOK {
				log.Infof("å¥åº·æ£€æŸ¥æˆåŠŸ! æ€»å…±å°è¯• %d æ¬¡, è€—æ—¶ %v",
					attempt, time.Since(startTime))
				return nil
			}

			log.Infof("å¥åº·æ£€æŸ¥å°è¯• %d: çŠ¶æ€ç  %d", attempt, resp.StatusCode)
		}

		select {
		case <-ctx.Done():
			return fmt.Errorf("å¥åº·æ£€æŸ¥è¶…æ—¶: %w", ctx.Err())
		case <-time.After(1 * time.Second):
			// ç»§ç»­é‡è¯•
		}
	}
}

func (g *GenericAPIServer) initRedisStore() error {
	ctx, cancel := context.WithCancel(context.Background())
	g.redisCancel = cancel
	defer func() {
		if r := recover(); r != nil {
			cancel()
			log.Errorf("Redisåˆå§‹åŒ–å¼‚å¸¸: %v", r)
		}
	}()

	// åˆå§‹åŒ–RedisCluster
	g.redis = &storage.RedisCluster{
		KeyPrefix: "genericapiserver:",
		HashKeys:  false,
		IsCache:   false,
	}

	// å¯åŠ¨Rediså¼‚æ­¥è¿æ¥ä»»åŠ¡
	go func() {
		log.Info("å¯åŠ¨Redisé›†ç¾¤å¼‚æ­¥è¿æ¥ä»»åŠ¡")
		storage.ConnectToRedis(ctx, g.options.RedisOptions)
		log.Warn("Redisé›†ç¾¤å¼‚æ­¥è¿æ¥ä»»åŠ¡é€€å‡ºï¼ˆå¯èƒ½ä¸Šä¸‹æ–‡å·²å–æ¶ˆï¼‰")
	}()

	// ç­‰å¾…åˆå§‹è¿æ¥å°è¯•å®Œæˆ
	log.Info("ç­‰å¾…Redisé›†ç¾¤åˆå§‹è¿æ¥å°è¯•...")
	time.Sleep(5 * time.Second)

	const (
		maxRetries    = 30
		retryInterval = 3 * time.Second
	)

	for retryCount := 0; retryCount < maxRetries; retryCount++ {
		// 1. æ£€æŸ¥è¿æ¥çŠ¶æ€
		if !storage.Connected() {
			log.Warnf("Redisé›†ç¾¤æœªè¿æ¥ï¼ˆå°è¯• %d/%dï¼‰", retryCount+1, maxRetries)
			if retryCount == maxRetries-1 {
				return fmt.Errorf("Redisé›†ç¾¤è¿æ¥å¤±è´¥ï¼šstorageæœªæ ‡è®°ä¸ºå·²è¿æ¥ï¼ˆé‡è¯•%dæ¬¡åï¼‰", maxRetries)
			}
			time.Sleep(retryInterval)
			continue
		}

		// 2. è·å–å®¢æˆ·ç«¯ - ä½¿ç”¨GetClient()æ–¹æ³•
		redisClient := g.redis.GetClient()
		if redisClient == nil {
			log.Warnf("Rediså®¢æˆ·ç«¯ä¸ºç©ºï¼ˆå°è¯• %d/%dï¼‰", retryCount+1, maxRetries)
			if retryCount == maxRetries-1 {
				return fmt.Errorf("Redisè¿æ¥å¤±è´¥ï¼šGetClient()è¿”å›ç©ºå®¢æˆ·ç«¯ï¼ˆé‡è¯•%dæ¬¡åï¼‰", maxRetries)
			}
			time.Sleep(retryInterval)
			continue
		}

		// 3. éªŒè¯è¿æ¥
		if err := g.pingRedis(ctx, redisClient); err != nil {
			log.Warnf("Redisè¿æ¥éªŒè¯å¤±è´¥ï¼ˆå°è¯• %d/%dï¼‰: %v", retryCount+1, maxRetries, err)
			if retryCount == maxRetries-1 {
				return fmt.Errorf("Redisè¿æ¥å¤±è´¥ï¼šPINGéªŒè¯å¤±è´¥ï¼ˆé‡è¯•%dæ¬¡åï¼‰: %v", maxRetries, err)
			}
			time.Sleep(retryInterval)
			continue
		}

		// 4. æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼Œè¿æ¥æˆåŠŸ
		log.Info("âœ… Redisé›†ç¾¤è¿æ¥æˆåŠŸä¸”éªŒè¯å¯ç”¨")
		go g.monitorRedisConnection(ctx)

		// 5. å¯åŠ¨Redisé›†ç¾¤ç›‘æ§
		g.setupRedisClusterMonitoring()

		go g.monitorRedisConnection(ctx)

		return nil
	}

	return fmt.Errorf("Redisè¿æ¥å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°(%d)", maxRetries)
}

// setupRedisClusterMonitoring è®¾ç½®Redisé›†ç¾¤ç›‘æ§
func (g *GenericAPIServer) setupRedisClusterMonitoring() {
	// ä»Redisé…ç½®ä¸­è·å–é›†ç¾¤èŠ‚ç‚¹åœ°å€
	nodes := g.options.RedisOptions.Addrs
	if len(nodes) == 0 {
		// å¦‚æœæ²¡æœ‰é…ç½®é›†ç¾¤åœ°å€ï¼Œä½¿ç”¨é»˜è®¤çš„å•èŠ‚ç‚¹åœ°å€
		nodes = []string{fmt.Sprintf("%s:%d", g.options.RedisOptions.Host, g.options.RedisOptions.Port)}
	}

	log.Infof("å¯åŠ¨Redisé›†ç¾¤ç›‘æ§ï¼ŒèŠ‚ç‚¹: %v", nodes)

	// åˆ›å»ºé›†ç¾¤ç›‘æ§å™¨
	monitor := metrics.NewRedisClusterMonitor(
		"generic_api_server_cluster", // é›†ç¾¤åç§°
		nodes,                        // é›†ç¾¤èŠ‚ç‚¹åœ°å€
		30*time.Second,               // æ¯30ç§’é‡‡é›†ä¸€æ¬¡
	)

	// å¯åŠ¨ç›‘æ§
	go monitor.Start(context.Background())

	log.Info("âœ… Redisé›†ç¾¤ç›‘æ§å·²å¯åŠ¨")
}

// pingRedis æ”¯æŒredis.UniversalClientç±»å‹
func (g *GenericAPIServer) pingRedis(ctx context.Context, client redis.UniversalClient) error {
	pingCtx, cancel := context.WithTimeout(ctx, 10*time.Second)
	defer cancel()

	// æ£€æŸ¥é›†ç¾¤çŠ¶æ€
	if clusterClient, ok := client.(*redis.ClusterClient); ok {
		// é›†ç¾¤æ¨¡å¼ï¼šæ£€æŸ¥é›†ç¾¤ä¿¡æ¯
		_, err := clusterClient.ClusterInfo(pingCtx).Result()
		if err != nil {
			return fmt.Errorf("é›†ç¾¤çŠ¶æ€æ£€æŸ¥å¤±è´¥: %v", err)
		}

		// å¯é€‰ï¼šå¯¹æ¯ä¸ªä¸»èŠ‚ç‚¹æ‰§è¡ŒPINGï¼ˆæ›´ä¸¥æ ¼çš„æ£€æŸ¥ï¼‰
		var lastError error
		nodeCount := 0

		err = clusterClient.ForEachMaster(pingCtx, func(ctx context.Context, nodeClient *redis.Client) error {
			nodeCount++
			if err := nodeClient.Ping(ctx).Err(); err != nil {
				log.Warnf("é›†ç¾¤èŠ‚ç‚¹ %d PING å¤±è´¥: %v", nodeCount, err)
				lastError = err
				// ç»§ç»­æ£€æŸ¥å…¶ä»–èŠ‚ç‚¹
			}
			return nil
		})

		if nodeCount == 0 {
			return fmt.Errorf("æœªæ‰¾åˆ°é›†ç¾¤èŠ‚ç‚¹")
		}

		// å¦‚æœè‡³å°‘æœ‰ä¸€ä¸ªèŠ‚ç‚¹æ­£å¸¸ï¼Œè®¤ä¸ºé›†ç¾¤å¯ç”¨
		if err != nil && lastError != nil {
			return fmt.Errorf("é›†ç¾¤èŠ‚ç‚¹æ£€æŸ¥å¼‚å¸¸: %v", lastError)
		}

		log.Debugf("Redisé›†ç¾¤å¥åº·æ£€æŸ¥å®Œæˆï¼Œå…±%dä¸ªèŠ‚ç‚¹", nodeCount)
		return nil
	}

	// å•æœºæ¨¡å¼æˆ–æ™®é€šå®¢æˆ·ç«¯
	return client.Ping(pingCtx).Err()
}

// æ‰“å°Kafkaé…ç½®ä¿¡æ¯
func (g *GenericAPIServer) printKafkaConfigInfo() {
	kafkaOpts := g.options.KafkaOptions
	log.Infof("ğŸ“Š Kafkaé…ç½®ä¿¡æ¯:")
	log.Infof("  è¿è¡Œæ¨¡å¼: %s", g.options.ServerRunOptions.Mode)
	log.Infof("  Brokers: %v", kafkaOpts.Brokers)
	log.Infof("  ä¸»é¢˜é…ç½®:")
	log.Infof("    - åˆ›å»º: %s", UserCreateTopic)
	log.Infof("    - æ›´æ–°: %s", UserUpdateTopic)
	log.Infof("    - åˆ é™¤: %s", UserDeleteTopic)
	log.Infof("    - é‡è¯•: %s", UserRetryTopic)
	log.Infof("  é…ç½®å‚æ•°:")
	log.Infof("    - æœ€å¤§é‡è¯•: %d", kafkaOpts.MaxRetries)
	log.Infof("    - Workeræ•°é‡: %d", kafkaOpts.WorkerCount)
	log.Infof("    - æ‰¹é‡å¤§å°: %d", kafkaOpts.BatchSize)
	log.Infof("    - æ‰¹é‡è¶…æ—¶: %v", kafkaOpts.BatchTimeout)
	log.Infof("    - ç¡®è®¤æœºåˆ¶: %d", kafkaOpts.RequiredAcks)
}
